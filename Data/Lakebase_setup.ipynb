{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lakebase Database Instance Setup\n",
        "Create Databricks Lakebase (PostgreSQL) instance, catalog, and tables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Variables forcefully reloaded from data_store_variables.ipynb\n"
          ]
        }
      ],
      "source": [
        "# Force reload of data_store_variables\n",
        "import sys\n",
        "import importlib\n",
        "\n",
        "# Remove from cache if exists\n",
        "if 'data_store_variables' in sys.modules:\n",
        "    del sys.modules['data_store_variables']\n",
        "\n",
        "\n",
        "print(\"\\n‚úÖ Variables forcefully reloaded from data_store_variables.ipynb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üìã CONFIGURATION VARIABLES\n",
            "======================================================================\n",
            "\n",
            "üèóÔ∏è  PROJECT:\n",
            "   PROJECT_NAME: telecom_iot\n",
            "\n",
            "üìö DATA CONFIGURATION:\n",
            "   CATALOG_NAME: kunal\n",
            "   SCHEMA_NAME: Telcom\n",
            "   VOLUME_NAME: raw_data\n",
            "   VOLUME_PATH: /Volumes/kunal/Telcom/raw_data\n",
            "   TABLE_NAME: kunal.Telcom.iot_data_synched_cont\n",
            "\n",
            "üë§ USER:\n",
            "   DB_USER: kunal.gaurav\n",
            "   DB_USER_EMAIL: kunal.gaurav@databricks.com\n",
            "   DB_USER_CLEAN: kunal-gaurav\n",
            "\n",
            "üñ•Ô∏è  APPLICATION:\n",
            "   APP_NAME: iot_dashboard\n",
            "   DATA_REFRESH_INTERVAL: 500 minutes\n",
            "\n",
            "üóÑÔ∏è  LAKEBASE CONFIGURATION:\n",
            "   INSTANCE_NAME: kunal-gaurav-lakebase-instance\n",
            "   INSTANCE_CAPACITY: CU_1\n",
            "   LAKEBASE_CATALOG_NAME: pg_lakebase_kunal-gaurav\n",
            "   SYNCED_TABLE_NAME: pg_lakebase_kunal-gaurav.Telcom.iot_data_synced\n",
            "   PG_TABLE_NAME: kunal.Telcom.iot_metadata\n",
            "======================================================================\n",
            "‚úÖ Catalog 'kunal' created or already exists\n",
            "‚úÖ Schema 'kunal.Telcom' created or already exists\n",
            "‚úÖ Table 'kunal.Telcom.iot_data_synched_cont' created or already exists\n",
            "\n",
            "üéâ Database setup complete!\n",
            "‚úÖ Volume 'kunal.Telcom.raw_data' created or already exists\n",
            "   Path: /Volumes/kunal/Telcom/raw_data\n"
          ]
        }
      ],
      "source": [
        "%run ./data_store_variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: databricks-sdk in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (0.73.0)\n",
            "Requirement already satisfied: requests<3,>=2.28.1 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from databricks-sdk) (2.32.5)\n",
            "Requirement already satisfied: google-auth~=2.0 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from databricks-sdk) (2.43.0)\n",
            "Requirement already satisfied: protobuf!=5.26.*,!=5.27.*,!=5.28.*,!=5.29.0,!=5.29.1,!=5.29.2,!=5.29.3,!=5.29.4,!=6.30.0,!=6.30.1,!=6.31.0,<7.0,>=4.25.8 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from databricks-sdk) (6.33.1)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk) (4.9.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk) (2025.11.12)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk) (0.6.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "‚úÖ Databricks SDK imported\n"
          ]
        }
      ],
      "source": [
        "%pip install databricks-sdk\n",
        "\n",
        "from databricks.sdk import WorkspaceClient\n",
        "from databricks.sdk.service.database import (\n",
        "    DatabaseInstance,\n",
        "    DatabaseCatalog,\n",
        "    DatabaseTable,\n",
        "    SyncedDatabaseTable)\n",
        "from databricks.sdk.service.database import (\n",
        "    DatabaseInstance,\n",
        "    DatabaseCatalog,\n",
        "    DatabaseTable,\n",
        "    SyncedDatabaseTable,\n",
        "    SyncedTableSpec,\n",
        "    NewPipelineSpec,\n",
        "    SyncedTableSchedulingPolicy  # ‚úÖ Add this import\n",
        ")\n",
        "import time\n",
        "\n",
        "print(\"‚úÖ Databricks SDK imported\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Connected to workspace: https://e2-demo-field-eng.cloud.databricks.com\n",
            "   User: kunal.gaurav@databricks.com\n"
          ]
        }
      ],
      "source": [
        "# Initialize Databricks Workspace Client\n",
        "w = WorkspaceClient()\n",
        "\n",
        "print(f\"‚úÖ Connected to workspace: {w.config.host}\")\n",
        "print(f\"   User: {w.current_user.me().user_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Configuration loaded:\n",
            "   Project: telecom_iot\n",
            "   Instance: kunal-gaurav-lakebase-instance\n",
            "   Capacity: CU_1\n",
            "   SYNCED_TABLE_NAME: pg_lakebase_kunal-gaurav.Telcom.iot_data_synced\n",
            "LAKEBASE_CATALOG_NAME: pg_lakebase_kunal-gaurav\n"
          ]
        }
      ],
      "source": [
        "# All variables are loaded from data_store_variables.ipynb\n",
        "\n",
        "\n",
        "\n",
        "print(f\"‚úÖ Configuration loaded:\")\n",
        "print(f\"   Project: {PROJECT_NAME}\")\n",
        "print(f\"   Instance: {INSTANCE_NAME}\")\n",
        "print(f\"   Capacity: {INSTANCE_CAPACITY}\")\n",
        "print(f\"   SYNCED_TABLE_NAME: {SYNCED_TABLE_NAME}\")\n",
        "print(f\"LAKEBASE_CATALOG_NAME: {LAKEBASE_CATALOG_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Database Instance 'kunal-gaurav-lakebase-instance' already exists\n",
            "   Instance ID: f60d62f1-e44a-43c7-813f-58138e0552fd\n",
            "   Capacity: CU_1\n",
            "   State: DatabaseInstanceState.AVAILABLE\n",
            "\n",
            "üíæ Instance Name: kunal-gaurav-lakebase-instance\n"
          ]
        }
      ],
      "source": [
        "# Check if database instance exists\n",
        "def get_database_instance_by_name(instance_name):\n",
        "    \"\"\"Check if database instance exists\"\"\"\n",
        "    for instance in w.database.list_database_instances():\n",
        "        if instance.name == instance_name:\n",
        "            return instance\n",
        "    return None\n",
        "\n",
        "# Check if instance exists\n",
        "existing_instance = get_database_instance_by_name(INSTANCE_NAME)\n",
        "\n",
        "if existing_instance:\n",
        "    print(f\"‚úÖ Database Instance '{INSTANCE_NAME}' already exists\")\n",
        "    print(f\"   Instance ID: {existing_instance.uid}\")\n",
        "    print(f\"   Capacity: {existing_instance.capacity}\")\n",
        "    print(f\"   State: {existing_instance.state}\")\n",
        "    instance = existing_instance\n",
        "else:\n",
        "    print(f\"üîÑ Creating Database Instance: {INSTANCE_NAME}...\")\n",
        "    print(f\"   Capacity: {INSTANCE_CAPACITY}\")\n",
        "    print(f\"   This may take 5-10 minutes...\")\n",
        "    \n",
        "    # Create database instance\n",
        "    instance = w.database.create_database_instance_and_wait(\n",
        "        database_instance=DatabaseInstance(\n",
        "            name=INSTANCE_NAME,\n",
        "            capacity=INSTANCE_CAPACITY\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Database Instance created successfully!\")\n",
        "    print(f\"   Instance Name: {instance.name}\")\n",
        "    print(f\"   Instance UID: {instance.uid}\")\n",
        "    print(f\"   Capacity: {instance.capacity}\")\n",
        "    print(f\"   State: {instance.state}\")\n",
        "\n",
        "# Save instance name for later use\n",
        "LAKEBASE_INSTANCE_NAME = instance.name\n",
        "print(f\"\\nüíæ Instance Name: {LAKEBASE_INSTANCE_NAME}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Setting up Database Catalog: pg_lakebase_kunal-gaurav...\n",
            "‚úÖ Database Catalog 'pg_lakebase_kunal-gaurav' already exists\n",
            "   Using existing catalog\n",
            "\n",
            "üíæ Lakebase Catalog: pg_lakebase_kunal-gaurav\n",
            "   Instance: kunal-gaurav-lakebase-instance\n"
          ]
        }
      ],
      "source": [
        "# Create or get database catalog\n",
        "# Use LAKEBASE_CATALOG_NAME from data_store_variables\n",
        "\n",
        "print(f\"üîÑ Setting up Database Catalog: {LAKEBASE_CATALOG_NAME}...\")\n",
        "\n",
        "try:\n",
        "    # Try to create database catalog\n",
        "    db_catalog = w.database.create_database_catalog(\n",
        "        catalog=DatabaseCatalog(\n",
        "            name=LAKEBASE_CATALOG_NAME,\n",
        "            database_instance_name=LAKEBASE_INSTANCE_NAME,\n",
        "            database_name=LAKEBASE_CATALOG_NAME,\n",
        "            create_database_if_not_exists=True\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Database Catalog created!\")\n",
        "    print(f\"   Catalog Name: {db_catalog.name}\")\n",
        "    print(f\"   Database Name: {db_catalog.database_name}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    error_msg = str(e)\n",
        "    \n",
        "    # Check if it's an \"already exists\" error\n",
        "    if \"already exists\" in error_msg.lower():\n",
        "        print(f\"‚úÖ Database Catalog '{LAKEBASE_CATALOG_NAME}' already exists\")\n",
        "        print(f\"   Using existing catalog\")\n",
        "        # Set db_catalog to None or a placeholder since we can't retrieve it\n",
        "        db_catalog = None\n",
        "    else:\n",
        "        # Re-raise if it's a different error\n",
        "        print(f\"‚ùå Unexpected error: {e}\")\n",
        "        raise\n",
        "\n",
        "print(f\"\\nüíæ Lakebase Catalog: {LAKEBASE_CATALOG_NAME}\")\n",
        "print(f\"   Instance: {LAKEBASE_INSTANCE_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Creating Synced Database Table: kunal.Telcom.iot_data_synced...\n",
            "‚úÖ Synced Table created!\n",
            "   Table Name: kunal.telcom.iot_data_synced\n",
            "   Source: kunal.Telcom.iot_data_synched_cont\n",
            "   Target Instance: kunal-gaurav-lakebase-instance\n",
            "   Scheduling: CONTINUOUS\n"
          ]
        }
      ],
      "source": [
        "# Create a synced table (syncs from UC Delta to PostgreSQL)\n",
        "# SYNCED_TABLE_NAME is already loaded from data_store_variables\n",
        "\n",
        "\n",
        "\n",
        "print(f\"üîÑ Creating Synced Database Table: {SYNCED_TABLE_NAME}...\")\n",
        "\n",
        "try:\n",
        "    # Define the pipeline specification for the sync\n",
        "    pipeline_spec = NewPipelineSpec(\n",
        "        # Location for pipeline checkpoints and logs\n",
        "        # Must have write permissions to this catalog/schema\n",
        "        storage_catalog=LAKEBASE_CATALOG_NAME,\n",
        "        storage_schema=SCHEMA_NAME\n",
        "    )\n",
        "    \n",
        "    # Create the synced table spec\n",
        "    synced_spec = SyncedTableSpec(\n",
        "        source_table_full_name=TABLE_NAME,  # Source Delta table\n",
        "      \n",
        "        primary_key_columns=[\"tower_id\", \"timestamp\"],  # Primary keys for upserts\n",
        "        create_database_objects_if_missing=True,  # Auto-create PG objects\n",
        "        scheduling_policy=SyncedTableSchedulingPolicy.CONTINUOUS,\n",
        "        new_pipeline_spec= pipeline_spec   # Options: CONTINUOUS, SNAPSHOT, TRIGGERED\n",
        "    )\n",
        "    \n",
        "    # Create the synced database table\n",
        "    synced_table = w.database.create_synced_database_table(\n",
        "        synced_table=SyncedDatabaseTable(\n",
        "            name=SYNCED_TABLE_NAME,  # UC catalog.schema.table name\n",
        "            database_instance_name=LAKEBASE_INSTANCE_NAME, \n",
        "            logical_database_name=LAKEBASE_CATALOG_NAME, # Lakebase instance\n",
        "            spec=synced_spec# ‚úÖ Use spec parameter\n",
        "        )\n",
        "        \n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Synced Table created!\")\n",
        "    print(f\"   Table Name: {synced_table.name}\")\n",
        "    print(f\"   Source: {TABLE_NAME}\")\n",
        "    print(f\"   Target Instance: {LAKEBASE_INSTANCE_NAME}\")\n",
        "    print(f\"   Scheduling: CONTINUOUS\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Error: {e}\")\n",
        "    print(f\"   Make sure source table '{TABLE_NAME}' exists and has data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Working with lakebase data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate credentials for the Lakebase instance\n",
        "instance = w.database.get_database_instance(name=LAKEBASE_INSTANCE_NAME)\n",
        "credential = w.database.generate_database_credential(\n",
        "    instance_names=[LAKEBASE_INSTANCE_NAME]\n",
        ")\n",
        "host = instance.read_write_dns\n",
        "port = 5432\n",
        "dbname = \"databricks_postgres\"\n",
        "user = DB_USER_EMAIL\n",
        "password = credential.token\n",
        "\n",
        "print(host)\n",
        "print(port)\n",
        "print(dbname)\n",
        "print(user)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Generating app.yml with connection values...\n",
            "‚úÖ app.yml generated successfully!\n",
            "   Path: ../lakebase_apps/app.yml\n",
            "   PGHOST: instance-f60d62f1-e44a-43c7-813f-58138e0552fd.database.cloud.databricks.com\n",
            "   PGDATABASE: pg_lakebase_kunal-gaurav\n",
            "   TABLE: kunal.Telcom.iot_data_synced\n"
          ]
        }
      ],
      "source": [
        "# Generate app.yml with connection values\n",
        "print(\"üìù Generating app.yml with connection values...\")\n",
        "\n",
        "# Get instance details\n",
        "instance = w.database.get_database_instance(name=LAKEBASE_INSTANCE_NAME)\n",
        "host = instance.read_write_dns\n",
        "port = 5432\n",
        "\n",
        "app_yml_content = f\"\"\"command:\n",
        "  - \"python\"\n",
        "  - \"app.py\"\n",
        "\n",
        "env:\n",
        "  # PostgreSQL Database (from DatabaseCatalog)\n",
        "  - name: PGDATABASE\n",
        "    value: \"{LAKEBASE_CATALOG_NAME}\"\n",
        "  \n",
        "  # Database User\n",
        "  - name: PGUSER\n",
        "    value: \"{DB_USER_EMAIL}\"\n",
        "  \n",
        "  # PostgreSQL Host (from Lakebase instance)\n",
        "  - name: PGHOST\n",
        "    value: \"{host}\"\n",
        "  \n",
        "  # PostgreSQL Port\n",
        "  - name: PGPORT\n",
        "    value: \"{port}\"\n",
        "  \n",
        "  # SSL Mode (required for Databricks)\n",
        "  - name: PGSSLMODE\n",
        "    value: \"require\"\n",
        "  \n",
        "  # Application Name\n",
        "  - name: PGAPPNAME\n",
        "    value: \"{APP_NAME}\"\n",
        "  \n",
        "  # Table Configuration\n",
        "  - name: SCHEMA_NAME\n",
        "    value: \"{CATALOG_NAME}.{SCHEMA_NAME}\"\n",
        "  \n",
        "  - name: TABLE_NAME\n",
        "    value: \"{SYNCED_TABLE_NAME.split('.')[-1]}\"\n",
        "\"\"\"\n",
        "\n",
        "# Write to file\n",
        "app_yml_path = \"../lakebase_apps/app.yml\"\n",
        "with open(app_yml_path, 'w') as f:\n",
        "    f.write(app_yml_content)\n",
        "\n",
        "print(f\"‚úÖ app.yml generated successfully!\")\n",
        "print(f\"   Path: {app_yml_path}\")\n",
        "print(f\"   PGHOST: {host}\")\n",
        "print(f\"   PGDATABASE: {LAKEBASE_CATALOG_NAME}\")\n",
        "print(f\"   TABLE: {SYNCED_TABLE_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting psycopg\n",
            "  Downloading psycopg-3.3.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from psycopg) (4.15.0)\n",
            "Downloading psycopg-3.3.2-py3-none-any.whl (212 kB)\n",
            "Installing collected packages: psycopg\n",
            "Successfully installed psycopg-3.3.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install psycopg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîê Setting up PostgreSQL Role for App Service Principal...\n",
            "‚úÖ Created PostgreSQL role for service principal\n",
            "‚úÖ Granted permissions to service principal\n",
            "\n",
            "üéâ Service principal role configured successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create PostgreSQL Role for Databricks App Service Principal\n",
        "import psycopg\n",
        "\n",
        "print(\"üîê Setting up PostgreSQL Role for App Service Principal...\")\n",
        "\n",
        "# Get connection\n",
        "instance = w.database.get_database_instance(name=LAKEBASE_INSTANCE_NAME)\n",
        "credential = w.database.generate_database_credential(instance_names=[LAKEBASE_INSTANCE_NAME])\n",
        "\n",
        "# Connect as admin user\n",
        "conn = psycopg.connect(\n",
        "    host=instance.read_write_dns,\n",
        "    port=5432,\n",
        "    dbname=LAKEBASE_CATALOG_NAME,\n",
        "    user=DB_USER_EMAIL,\n",
        "    password=credential.token,\n",
        "    sslmode=\"require\"\n",
        ")\n",
        "\n",
        "conn.autocommit = True\n",
        "cur = conn.cursor()\n",
        "\n",
        "# Your app's service principal ID\n",
        "APP_SERVICE_PRINCIPAL = \"1e2bd8c8-1a42-4d68-af82-6d83250ad4c2\"\n",
        "\n",
        "try:\n",
        "    # Check if role exists\n",
        "    cur.execute(f\"\"\"\n",
        "        SELECT 1 FROM pg_roles WHERE rolname = '{APP_SERVICE_PRINCIPAL}'\n",
        "    \"\"\")\n",
        "    \n",
        "    if cur.fetchone():\n",
        "        print(f\"   Role already exists\")\n",
        "    else:\n",
        "        # Create the role for the service principal\n",
        "        cur.execute(f'CREATE ROLE \"{APP_SERVICE_PRINCIPAL}\" WITH LOGIN')\n",
        "        print(f\"‚úÖ Created PostgreSQL role for service principal\")\n",
        "    \n",
        "    # Grant necessary permissions\n",
        "    cur.execute(f'GRANT CONNECT ON DATABASE \"{LAKEBASE_CATALOG_NAME}\" TO \"{APP_SERVICE_PRINCIPAL}\"')\n",
        "    cur.execute(f'GRANT USAGE ON SCHEMA telcom TO \"{APP_SERVICE_PRINCIPAL}\"')\n",
        "    cur.execute(f'GRANT SELECT ON ALL TABLES IN SCHEMA telcom TO \"{APP_SERVICE_PRINCIPAL}\"')\n",
        "    \n",
        "    print(f\"‚úÖ Granted permissions to service principal\")\n",
        "    print(f\"\\nüéâ Service principal role configured successfully!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "finally:\n",
        "    cur.close()\n",
        "    conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
