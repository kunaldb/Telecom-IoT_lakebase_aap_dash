{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ContentPulse Data Ingestion\n",
        "Load JSON files from Volume into Delta Table using Spark Streaming\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì∞ ContentPulse Project Configuration\n",
            "   Project: ContentPulse_Publishing_Analytics\n",
            "   User: kunal.gaurav@databricks.com\n",
            "   Volume: /Volumes/kunal/publishing/publishing_data\n",
            "   Table: kunal.publishing.content_engagement_events\n",
            "üóÑÔ∏è  Lakebase Configuration\n",
            "   Instance: kunal-gaurav-lakebase-instance\n",
            "   Catalog: pg_contentpulse_kunal-gaurav\n",
            "   Synced Table: kunal.publishing.content_engagement_synced\n",
            "‚úÖ Catalog 'kunal' ready\n",
            "‚úÖ Schema 'kunal.publishing' ready\n",
            "‚úÖ Volume '/Volumes/kunal/publishing/publishing_data' ready\n",
            "‚úÖ Table 'kunal.publishing.content_engagement_events' ready with Change Data Feed enabled\n"
          ]
        }
      ],
      "source": [
        "%run ./contentpulse_config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Source Volume: /Volumes/kunal/publishing/publishing_data/CONTENT_EVENTS\n",
            "üíæ Checkpoint: /Volumes/kunal/publishing/publishing_data/checkpoint\n",
            "‚úÖ Streaming started: contentpulse_streaming\n",
            "üìä Query ID: 23e94ea2-d9e4-4be8-8e32-51b18a0b65c9\n",
            "üéØ Target Table: kunal.publishing.content_engagement_events\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, from_json\n",
        "from pyspark.sql.types import StructType, StringType, DoubleType, IntegerType, TimestampType, BooleanType\n",
        "\n",
        "# Define schema matching ContentPulse data generation\n",
        "schema = StructType() \\\n",
        "    .add(\"event_id\", StringType()) \\\n",
        "    .add(\"timestamp\", TimestampType()) \\\n",
        "    .add(\"event_type\", StringType()) \\\n",
        "    .add(\"reader_id\", StringType()) \\\n",
        "    .add(\"article_id\", StringType()) \\\n",
        "    .add(\"article_title\", StringType()) \\\n",
        "    .add(\"category\", StringType()) \\\n",
        "    .add(\"publication\", StringType()) \\\n",
        "    .add(\"device_type\", StringType()) \\\n",
        "    .add(\"country\", StringType()) \\\n",
        "    .add(\"city\", StringType()) \\\n",
        "    .add(\"latitude\", DoubleType()) \\\n",
        "    .add(\"longitude\", DoubleType()) \\\n",
        "    .add(\"time_on_page_seconds\", IntegerType()) \\\n",
        "    .add(\"scroll_depth_percent\", IntegerType()) \\\n",
        "    .add(\"num_comments\", IntegerType()) \\\n",
        "    .add(\"num_shares\", IntegerType()) \\\n",
        "    .add(\"ad_impressions\", IntegerType()) \\\n",
        "    .add(\"estimated_ad_revenue\", DoubleType()) \\\n",
        "    .add(\"is_subscriber\", BooleanType()) \\\n",
        "    .add(\"subscription_tier\", StringType())\n",
        "\n",
        "# Volume path for Content Events (matches data generation path)\n",
        "volume_path = f\"{VOLUME_PATH}/CONTENT_EVENTS\"\n",
        "print(f\"üìÅ Source Volume: {volume_path}\")\n",
        "\n",
        "# Checkpoint location\n",
        "checkpoint_path = f\"{VOLUME_PATH}/checkpoint\"\n",
        "print(f\"üíæ Checkpoint: {checkpoint_path}\")\n",
        "\n",
        "# Read from JSON files using Auto Loader (cloudFiles)\n",
        "stream_df = (spark.readStream\n",
        "    .format(\"cloudFiles\")\n",
        "    .schema(schema)\n",
        "    .option(\"cloudFiles.format\", \"json\")\n",
        "    .load(volume_path))\n",
        "\n",
        "# Write stream to Delta table\n",
        "query = (stream_df\n",
        " .writeStream\n",
        " .format(\"delta\")\n",
        " .outputMode(\"append\")\n",
        " .option(\"checkpointLocation\", checkpoint_path)\n",
        " .trigger(processingTime=\"10 seconds\")  # Process every 10 seconds\n",
        " .queryName(\"contentpulse_streaming\")  # Named query\n",
        " .table(FULL_TABLE_NAME)\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Streaming started: {query.name}\")\n",
        "print(f\"üìä Query ID: {query.id}\")\n",
        "print(f\"üéØ Target Table: {FULL_TABLE_NAME}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2181: UserWarning: Spark Connect Session expired on the server. Please generate a new session by detaching and reattaching the compute if in a Databricks notebook or job or by calling DatabricksSession.builder.getOrCreate() if using Databricks Connect.\n",
            "  warnings.warn(\n",
            "/Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py:253: UserWarning: ReleaseExecute failed with exception: <_InactiveRpcError of RPC that terminated with:\n",
            "\tstatus = StatusCode.INTERNAL\n",
            "\tdetails = \"[INVALID_HANDLE.SESSION_CLOSED] The handle 3b868867-0b3b-4a07-aa20-9db4bcc88f4a is invalid. Session was closed. SQLSTATE: HY000\"\n",
            "\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_status:13, grpc_message:\"[INVALID_HANDLE.SESSION_CLOSED] The handle 3b868867-0b3b-4a07-aa20-9db4bcc88f4a is invalid. Session was closed. SQLSTATE: HY000\"}\"\n",
            ">.\n",
            "  warnings.warn(f\"ReleaseExecute failed with exception: {e}.\")\n"
          ]
        },
        {
          "ename": "SparkConnectGrpcException",
          "evalue": "(org.apache.spark.SparkSQLException) [INVALID_HANDLE.SESSION_CLOSED] The handle 3b868867-0b3b-4a07-aa20-9db4bcc88f4a is invalid. Session was closed. SQLSTATE: HY000",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mSparkConnectGrpcException\u001b[39m                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Get query stats\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m query_status = \u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müìä STREAMING QUERY STATUS\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages/pyspark/sql/connect/streaming/query.py:105\u001b[39m, in \u001b[36mStreamingQuery.status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstatus\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     proto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fetch_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    107\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m: proto.status_message,\n\u001b[32m    108\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33misDataAvailable\u001b[39m\u001b[33m\"\u001b[39m: proto.is_data_available,\n\u001b[32m    109\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33misTriggerActive\u001b[39m\u001b[33m\"\u001b[39m: proto.is_trigger_active,\n\u001b[32m    110\u001b[39m     }\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages/pyspark/sql/connect/streaming/query.py:198\u001b[39m, in \u001b[36mStreamingQuery._fetch_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    196\u001b[39m cmd = pb2.StreamingQueryCommand()\n\u001b[32m    197\u001b[39m cmd.status = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_streaming_query_cmd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m.status\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages/pyspark/sql/connect/streaming/query.py:207\u001b[39m, in \u001b[36mStreamingQuery._execute_streaming_query_cmd\u001b[39m\u001b[34m(self, cmd)\u001b[39m\n\u001b[32m    205\u001b[39m exec_cmd = pb2.Command()\n\u001b[32m    206\u001b[39m exec_cmd.streaming_query_command.CopyFrom(cmd)\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m (_, properties, _) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec_cmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(pb2.StreamingQueryCommandResult, properties[\u001b[33m\"\u001b[39m\u001b[33mstreaming_query_command_result\u001b[39m\u001b[33m\"\u001b[39m])\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1306\u001b[39m, in \u001b[36mSparkConnectClient.execute_command\u001b[39m\u001b[34m(self, command, observations, extra_request_metadata)\u001b[39m\n\u001b[32m   1304\u001b[39m     req.user_context.user_id = \u001b[38;5;28mself\u001b[39m._user_id\n\u001b[32m   1305\u001b[39m req.plan.command.CopyFrom(command)\n\u001b[32m-> \u001b[39m\u001b[32m1306\u001b[39m data, _, metrics, observed_metrics, properties = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_and_fetch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1307\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_request_metadata\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[38;5;66;03m# Create a query execution object.\u001b[39;00m\n\u001b[32m   1310\u001b[39m ei = ExecutionInfo(metrics, observed_metrics)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1764\u001b[39m, in \u001b[36mSparkConnectClient._execute_and_fetch\u001b[39m\u001b[34m(self, req, observations, extra_request_metadata, self_destruct)\u001b[39m\n\u001b[32m   1761\u001b[39m properties: Dict[\u001b[38;5;28mstr\u001b[39m, Any] = {}\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Progress(handlers=\u001b[38;5;28mself\u001b[39m._progress_handlers, operation_id=req.operation_id) \u001b[38;5;28;01mas\u001b[39;00m progress:\n\u001b[32m-> \u001b[39m\u001b[32m1764\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_and_fetch_as_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1765\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_request_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress\u001b[49m\n\u001b[32m   1766\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1767\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStructType\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1768\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:1740\u001b[39m, in \u001b[36mSparkConnectClient._execute_and_fetch_as_iterator\u001b[39m\u001b[34m(self, req, observations, extra_request_metadata, progress)\u001b[39m\n\u001b[32m   1738\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m kb\n\u001b[32m   1739\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m-> \u001b[39m\u001b[32m1740\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2056\u001b[39m, in \u001b[36mSparkConnectClient._handle_error\u001b[39m\u001b[34m(self, error)\u001b[39m\n\u001b[32m   2054\u001b[39m \u001b[38;5;28mself\u001b[39m.thread_local.inside_error_handling = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2055\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, grpc.RpcError):\n\u001b[32m-> \u001b[39m\u001b[32m2056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_rpc_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2057\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   2058\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCannot invoke RPC\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(error) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(error):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2137\u001b[39m, in \u001b[36mSparkConnectClient._handle_rpc_error\u001b[39m\u001b[34m(self, rpc_error)\u001b[39m\n\u001b[32m   2133\u001b[39m             d.Unpack(info)\n\u001b[32m   2135\u001b[39m             \u001b[38;5;28mself\u001b[39m._handle_rpc_error_with_error_info(info, status.message, status_code)  \u001b[38;5;66;03m# EDGE\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2137\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m convert_exception(\n\u001b[32m   2138\u001b[39m                 info,\n\u001b[32m   2139\u001b[39m                 status.message,\n\u001b[32m   2140\u001b[39m                 \u001b[38;5;28mself\u001b[39m._fetch_enriched_error(info),\n\u001b[32m   2141\u001b[39m                 \u001b[38;5;28mself\u001b[39m._display_server_stack_trace(),\n\u001b[32m   2142\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2144\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SparkConnectGrpcException(\n\u001b[32m   2145\u001b[39m         message=status.message,\n\u001b[32m   2146\u001b[39m         sql_state=ErrorCode.CLIENT_UNEXPECTED_MISSING_SQL_STATE,  \u001b[38;5;66;03m# EDGE\u001b[39;00m\n\u001b[32m   2147\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[31mSparkConnectGrpcException\u001b[39m: (org.apache.spark.SparkSQLException) [INVALID_HANDLE.SESSION_CLOSED] The handle 3b868867-0b3b-4a07-aa20-9db4bcc88f4a is invalid. Session was closed. SQLSTATE: HY000"
          ]
        }
      ],
      "source": [
        "# Get query stats\n",
        "query_status = query.status\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üìä STREAMING QUERY STATUS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Query Name: {query.name}\")\n",
        "print(f\"Query ID: {query.id}\")\n",
        "print(f\"Is Active: {query.isActive}\")\n",
        "print(f\"Message: {query_status['message']}\")\n",
        "print(f\"Data Available: {query_status['isDataAvailable']}\")\n",
        "print(f\"Trigger Active: {query_status['isTriggerActive']}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Get recent progress\n",
        "recent_progress = query.recentProgress\n",
        "if recent_progress:\n",
        "    latest = recent_progress[-1]\n",
        "    print(\"\\nüìà LATEST PROGRESS:\")\n",
        "    print(f\"Batch ID: {latest.get('batchId', 'N/A')}\")\n",
        "    print(f\"Input Rows: {latest.get('numInputRows', 0)}\")\n",
        "    print(f\"Processing Time: {latest.get('durationMs', {}).get('triggerExecution', 'N/A')} ms\")\n",
        "    print(f\"Timestamp: {latest.get('timestamp', 'N/A')}\")\n",
        "else:\n",
        "    print(\"\\n‚è≥ No progress yet - waiting for data...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Sample data from Delta table:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>event_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>event_type</th>\n",
              "      <th>reader_id</th>\n",
              "      <th>article_id</th>\n",
              "      <th>article_title</th>\n",
              "      <th>category</th>\n",
              "      <th>publication</th>\n",
              "      <th>device_type</th>\n",
              "      <th>country</th>\n",
              "      <th>city</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>time_on_page_seconds</th>\n",
              "      <th>scroll_depth_percent</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>num_shares</th>\n",
              "      <th>ad_impressions</th>\n",
              "      <th>estimated_ad_revenue</th>\n",
              "      <th>is_subscriber</th>\n",
              "      <th>subscription_tier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>evt_df086c127063</td>\n",
              "      <td>2025-12-16 12:59:31.248774</td>\n",
              "      <td>page_view</td>\n",
              "      <td>reader_8894</td>\n",
              "      <td>art_6986</td>\n",
              "      <td>Oscar Predictions: Who Will Win Big?</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Architectural Digest</td>\n",
              "      <td>mobile</td>\n",
              "      <td>USA</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>34.0522</td>\n",
              "      <td>-118.2437</td>\n",
              "      <td>229</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.39</td>\n",
              "      <td>False</td>\n",
              "      <td>free</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>evt_eeebe583685a</td>\n",
              "      <td>2025-12-16 12:59:48.763339</td>\n",
              "      <td>page_view</td>\n",
              "      <td>reader_59963</td>\n",
              "      <td>art_8714</td>\n",
              "      <td>Travel Safety Tips for Solo Travelers</td>\n",
              "      <td>Travel</td>\n",
              "      <td>Architectural Digest</td>\n",
              "      <td>mobile</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>S√£o Paulo</td>\n",
              "      <td>-23.5505</td>\n",
              "      <td>-46.6333</td>\n",
              "      <td>597</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.26</td>\n",
              "      <td>True</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>evt_6e11e17eda74</td>\n",
              "      <td>2025-12-16 12:59:10.648137</td>\n",
              "      <td>page_view</td>\n",
              "      <td>reader_83240</td>\n",
              "      <td>art_1177</td>\n",
              "      <td>Budget Travel: See the World for Less</td>\n",
              "      <td>Travel</td>\n",
              "      <td>Architectural Digest</td>\n",
              "      <td>mobile</td>\n",
              "      <td>Australia</td>\n",
              "      <td>Sydney</td>\n",
              "      <td>-33.8688</td>\n",
              "      <td>151.2093</td>\n",
              "      <td>324</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.24</td>\n",
              "      <td>True</td>\n",
              "      <td>basic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>evt_8fb4263b2bc6</td>\n",
              "      <td>2025-12-16 12:59:44.996809</td>\n",
              "      <td>comment</td>\n",
              "      <td>reader_18603</td>\n",
              "      <td>art_3867</td>\n",
              "      <td>Startup Success Stories: Lessons Learned</td>\n",
              "      <td>Business</td>\n",
              "      <td>The New Yorker</td>\n",
              "      <td>mobile</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>S√£o Paulo</td>\n",
              "      <td>-23.5505</td>\n",
              "      <td>-46.6333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>True</td>\n",
              "      <td>premium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>evt_4a7696c364d3</td>\n",
              "      <td>2025-12-16 12:59:16.196076</td>\n",
              "      <td>share</td>\n",
              "      <td>reader_72298</td>\n",
              "      <td>art_4850</td>\n",
              "      <td>AI Revolution: How ChatGPT is Changing Everything</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Architectural Digest</td>\n",
              "      <td>mobile</td>\n",
              "      <td>UK</td>\n",
              "      <td>London</td>\n",
              "      <td>51.5074</td>\n",
              "      <td>-0.1278</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>True</td>\n",
              "      <td>free</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>evt_bd160935546b</td>\n",
              "      <td>2025-12-16 12:59:28.483958</td>\n",
              "      <td>page_view</td>\n",
              "      <td>reader_17693</td>\n",
              "      <td>art_1073</td>\n",
              "      <td>Healthy Eating: Nutritionist's Top Tips</td>\n",
              "      <td>Food</td>\n",
              "      <td>Architectural Digest</td>\n",
              "      <td>mobile</td>\n",
              "      <td>USA</td>\n",
              "      <td>New York</td>\n",
              "      <td>40.7128</td>\n",
              "      <td>-74.0060</td>\n",
              "      <td>552</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.46</td>\n",
              "      <td>False</td>\n",
              "      <td>premium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>evt_a9033b53e5a6</td>\n",
              "      <td>2025-12-16 12:59:38.907894</td>\n",
              "      <td>scroll</td>\n",
              "      <td>reader_32741</td>\n",
              "      <td>art_3328</td>\n",
              "      <td>The Return of Y2K Style: What's Hot Now</td>\n",
              "      <td>Fashion</td>\n",
              "      <td>Architectural Digest</td>\n",
              "      <td>desktop</td>\n",
              "      <td>USA</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>34.0522</td>\n",
              "      <td>-118.2437</td>\n",
              "      <td>0</td>\n",
              "      <td>94</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>True</td>\n",
              "      <td>free</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>evt_839b2466fd2e</td>\n",
              "      <td>2025-12-16 12:59:50.818020</td>\n",
              "      <td>page_view</td>\n",
              "      <td>reader_25274</td>\n",
              "      <td>art_2978</td>\n",
              "      <td>The Future of Electric Vehicles</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Bon App√©tit</td>\n",
              "      <td>mobile</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Toronto</td>\n",
              "      <td>43.6532</td>\n",
              "      <td>-79.3832</td>\n",
              "      <td>135</td>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.15</td>\n",
              "      <td>False</td>\n",
              "      <td>basic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>evt_1c01b99acebf</td>\n",
              "      <td>2025-12-16 13:00:20.143518</td>\n",
              "      <td>subscribe</td>\n",
              "      <td>reader_50994</td>\n",
              "      <td>art_6171</td>\n",
              "      <td>Sports Technology: The Future of Athletics</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Glamour</td>\n",
              "      <td>desktop</td>\n",
              "      <td>Australia</td>\n",
              "      <td>Sydney</td>\n",
              "      <td>-33.8688</td>\n",
              "      <td>151.2093</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>False</td>\n",
              "      <td>basic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>evt_9971fb868f9a</td>\n",
              "      <td>2025-12-16 12:59:49.274358</td>\n",
              "      <td>scroll</td>\n",
              "      <td>reader_28584</td>\n",
              "      <td>art_8234</td>\n",
              "      <td>Super Bowl Preview: Who Will Win?</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Architectural Digest</td>\n",
              "      <td>mobile</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Toronto</td>\n",
              "      <td>43.6532</td>\n",
              "      <td>-79.3832</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>False</td>\n",
              "      <td>basic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "DataFrame[event_id: string, timestamp: timestamp, event_type: string, reader_id: string, article_id: string, article_title: string, category: string, publication: string, device_type: string, country: string, city: string, latitude: double, longitude: double, time_on_page_seconds: int, scroll_depth_percent: int, num_comments: int, num_shares: int, ad_impressions: int, estimated_ad_revenue: double, is_subscriber: boolean, subscription_tier: string]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Check table data\n",
        "print(\"üìä Sample data from Delta table:\")\n",
        "display(spark.sql(f\"SELECT * FROM {FULL_TABLE_NAME} LIMIT 10\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚èπÔ∏è  Streaming query 'contentpulse_streaming' stopped successfully\n",
            "   Final status: False\n",
            "\n",
            "‚úÖ No active streaming queries\n"
          ]
        }
      ],
      "source": [
        "# Stop the streaming query (run this when you want to stop)\n",
        "try:\n",
        "    query.stop()\n",
        "    print(f\"‚èπÔ∏è  Streaming query '{query.name}' stopped successfully\")\n",
        "    print(f\"   Final status: {query.isActive}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error stopping query: {e}\")\n",
        "\n",
        "# Verify all streaming queries are stopped\n",
        "active_queries = spark.streams.active\n",
        "if active_queries:\n",
        "    print(f\"\\n‚ö†Ô∏è  Still {len(active_queries)} active streaming queries:\")\n",
        "    for q in active_queries:\n",
        "        print(f\"   - {q.name} (ID: {q.id})\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ No active streaming queries\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
