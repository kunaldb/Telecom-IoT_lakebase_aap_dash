{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ContentPulse Lakebase Setup\n",
        "Create Databricks Lakebase catalog and synced tables for ContentPulse dashboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Variables forcefully reloaded from contentpulse_config.ipynb\n"
          ]
        }
      ],
      "source": [
        "# Force reload of contentpulse_config\n",
        "import sys\n",
        "import importlib\n",
        "\n",
        "# Remove from cache if exists\n",
        "if 'contentpulse_config' in sys.modules:\n",
        "    del sys.modules['contentpulse_config']\n",
        "\n",
        "print(\"\\n‚úÖ Variables forcefully reloaded from contentpulse_config.ipynb\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì∞ ContentPulse Project Configuration\n",
            "   Project: ContentPulse_Publishing_Analytics\n",
            "   User: kunal.gaurav@databricks.com\n",
            "   Volume: /Volumes/kunal/publishing/publishing_data\n",
            "   Table: kunal.publishing.content_engagement_events\n",
            "üóÑÔ∏è  Lakebase Configuration\n",
            "   Instance: kunal-gaurav-lakebase-instance\n",
            "   Catalog: pg_contentpulse_kunal-gaurav\n",
            "   Synced Table: kunal.publishing.content_engagement_synced\n",
            "‚úÖ Catalog 'kunal' ready\n",
            "‚úÖ Schema 'kunal.publishing' ready\n",
            "‚úÖ Volume '/Volumes/kunal/publishing/publishing_data' ready\n",
            "‚úÖ Table 'kunal.publishing.content_engagement_events' ready with Change Data Feed enabled\n"
          ]
        }
      ],
      "source": [
        "%run ./contentpulse_config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: databricks-sdk in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (0.73.0)\n",
            "Requirement already satisfied: requests<3,>=2.28.1 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from databricks-sdk) (2.32.5)\n",
            "Requirement already satisfied: google-auth~=2.0 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from databricks-sdk) (2.43.0)\n",
            "Requirement already satisfied: protobuf!=5.26.*,!=5.27.*,!=5.28.*,!=5.29.0,!=5.29.1,!=5.29.2,!=5.29.3,!=5.29.4,!=6.30.0,!=6.30.1,!=6.31.0,<7.0,>=4.25.8 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from databricks-sdk) (6.33.1)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk) (4.9.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk) (2025.11.12)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /Users/kunal.gaurav/Documents/Cursor/Telecom IoT_lakebase_aap_dash/.venv/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk) (0.6.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "‚úÖ Databricks SDK imported\n"
          ]
        }
      ],
      "source": [
        "%pip install databricks-sdk\n",
        "\n",
        "from databricks.sdk import WorkspaceClient\n",
        "from databricks.sdk.service.database import (\n",
        "    DatabaseInstance,\n",
        "    DatabaseCatalog,\n",
        "    DatabaseTable,\n",
        "    SyncedDatabaseTable,\n",
        "    SyncedTableSpec,\n",
        "    NewPipelineSpec,\n",
        "    SyncedTableSchedulingPolicy\n",
        ")\n",
        "import time\n",
        "\n",
        "print(\"‚úÖ Databricks SDK imported\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Connected to workspace: https://e2-demo-field-eng.cloud.databricks.com\n",
            "   User: kunal.gaurav@databricks.com\n"
          ]
        }
      ],
      "source": [
        "# Initialize Databricks Workspace Client\n",
        "w = WorkspaceClient()\n",
        "\n",
        "print(f\"‚úÖ Connected to workspace: {w.config.host}\")\n",
        "print(f\"   User: {w.current_user.me().user_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ ContentPulse Configuration loaded:\n",
            "   Project: ContentPulse_Publishing_Analytics\n",
            "   Instance: kunal-gaurav-lakebase-instance\n",
            "   Capacity: CU_1\n",
            "   Source Table: kunal.publishing.content_engagement_events\n",
            "   Synced Table: kunal.publishing.content_engagement_synced\n",
            "   Lakebase Catalog: pg_contentpulse_kunal-gaurav\n"
          ]
        }
      ],
      "source": [
        "# Display loaded configuration\n",
        "print(f\"‚úÖ ContentPulse Configuration loaded:\")\n",
        "print(f\"   Project: {PROJECT_NAME}\")\n",
        "print(f\"   Instance: {INSTANCE_NAME}\")\n",
        "print(f\"   Capacity: {INSTANCE_CAPACITY}\")\n",
        "print(f\"   Source Table: {FULL_TABLE_NAME}\")\n",
        "print(f\"   Synced Table: {SYNCED_TABLE_NAME}\")\n",
        "print(f\"   Lakebase Catalog: {LAKEBASE_CATALOG_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Check/Use Existing Lakebase Instance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Database Instance 'kunal-gaurav-lakebase-instance' already exists\n",
            "   Instance ID: f60d62f1-e44a-43c7-813f-58138e0552fd\n",
            "   Capacity: CU_1\n",
            "   State: DatabaseInstanceState.AVAILABLE\n",
            "   üìù Reusing existing instance for ContentPulse\n",
            "\n",
            "üíæ Instance Name: kunal-gaurav-lakebase-instance\n"
          ]
        }
      ],
      "source": [
        "# Check if database instance exists\n",
        "def get_database_instance_by_name(instance_name):\n",
        "    \"\"\"Check if database instance exists\"\"\"\n",
        "    for instance in w.database.list_database_instances():\n",
        "        if instance.name == instance_name:\n",
        "            return instance\n",
        "    return None\n",
        "\n",
        "# Check if instance exists\n",
        "existing_instance = get_database_instance_by_name(INSTANCE_NAME)\n",
        "\n",
        "if existing_instance:\n",
        "    print(f\"‚úÖ Database Instance '{INSTANCE_NAME}' already exists\")\n",
        "    print(f\"   Instance ID: {existing_instance.uid}\")\n",
        "    print(f\"   Capacity: {existing_instance.capacity}\")\n",
        "    print(f\"   State: {existing_instance.state}\")\n",
        "    print(f\"   üìù Reusing existing instance for ContentPulse\")\n",
        "    instance = existing_instance\n",
        "else:\n",
        "    print(f\"üîÑ Creating Database Instance: {INSTANCE_NAME}...\")\n",
        "    print(f\"   Capacity: {INSTANCE_CAPACITY}\")\n",
        "    print(f\"   This may take 5-10 minutes...\")\n",
        "    \n",
        "    # Create database instance\n",
        "    instance = w.database.create_database_instance_and_wait(\n",
        "        database_instance=DatabaseInstance(\n",
        "            name=INSTANCE_NAME,\n",
        "            capacity=INSTANCE_CAPACITY\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Database Instance created successfully!\")\n",
        "    print(f\"   Instance Name: {instance.name}\")\n",
        "    print(f\"   Instance UID: {instance.uid}\")\n",
        "    print(f\"   Capacity: {instance.capacity}\")\n",
        "    print(f\"   State: {instance.state}\")\n",
        "\n",
        "# Save instance name for later use\n",
        "LAKEBASE_INSTANCE_NAME = instance.name\n",
        "print(f\"\\nüíæ Instance Name: {LAKEBASE_INSTANCE_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create ContentPulse Database Catalog\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Setting up Database Catalog: pg_contentpulse_kunal-gaurav...\n",
            "‚úÖ Database Catalog created!\n",
            "   Catalog Name: pg_contentpulse_kunal-gaurav\n",
            "   Database Name: pg_contentpulse_kunal-gaurav\n",
            "\n",
            "üíæ Lakebase Catalog: pg_contentpulse_kunal-gaurav\n",
            "   Instance: kunal-gaurav-lakebase-instance\n"
          ]
        }
      ],
      "source": [
        "# Create or get database catalog for ContentPulse\n",
        "print(f\"üîÑ Setting up Database Catalog: {LAKEBASE_CATALOG_NAME}...\")\n",
        "\n",
        "try:\n",
        "    # Try to create database catalog\n",
        "    db_catalog = w.database.create_database_catalog(\n",
        "        catalog=DatabaseCatalog(\n",
        "            name=LAKEBASE_CATALOG_NAME,\n",
        "            database_instance_name=LAKEBASE_INSTANCE_NAME,\n",
        "            database_name=LAKEBASE_CATALOG_NAME,\n",
        "            create_database_if_not_exists=True\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Database Catalog created!\")\n",
        "    print(f\"   Catalog Name: {db_catalog.name}\")\n",
        "    print(f\"   Database Name: {db_catalog.database_name}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    error_msg = str(e)\n",
        "    \n",
        "    # Check if it's an \"already exists\" error\n",
        "    if \"already exists\" in error_msg.lower():\n",
        "        print(f\"‚úÖ Database Catalog '{LAKEBASE_CATALOG_NAME}' already exists\")\n",
        "        print(f\"   Using existing catalog\")\n",
        "        db_catalog = None\n",
        "    else:\n",
        "        # Re-raise if it's a different error\n",
        "        print(f\"‚ùå Unexpected error: {e}\")\n",
        "        raise\n",
        "\n",
        "print(f\"\\nüíæ Lakebase Catalog: {LAKEBASE_CATALOG_NAME}\")\n",
        "print(f\"   Instance: {LAKEBASE_INSTANCE_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Synced Table (Delta ‚Üí PostgreSQL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Creating Synced Database Table: kunal.publishing.content_engagement_synced...\n",
            "   Source Table: kunal.publishing.content_engagement_events\n",
            "‚úÖ Synced Table created!\n",
            "   Table Name: kunal.publishing.content_engagement_synced\n",
            "   Source: kunal.publishing.content_engagement_events\n",
            "   Target Instance: kunal-gaurav-lakebase-instance\n",
            "   Scheduling: CONTINUOUS\n",
            "   Primary Keys: event_id, timestamp\n"
          ]
        }
      ],
      "source": [
        "# Create a synced table (syncs from UC Delta to PostgreSQL)\n",
        "print(f\"üîÑ Creating Synced Database Table: {SYNCED_TABLE_NAME}...\")\n",
        "print(f\"   Source Table: {FULL_TABLE_NAME}\")\n",
        "\n",
        "try:\n",
        "    # Define the pipeline specification for the sync\n",
        "    pipeline_spec = NewPipelineSpec(\n",
        "        # Location for pipeline checkpoints and logs\n",
        "        storage_catalog=LAKEBASE_CATALOG_NAME,\n",
        "        storage_schema=SCHEMA_NAME\n",
        "    )\n",
        "    \n",
        "    # Create the synced table spec\n",
        "    synced_spec = SyncedTableSpec(\n",
        "        source_table_full_name=FULL_TABLE_NAME,  # Source Delta table\n",
        "        primary_key_columns=[\"event_id\", \"timestamp\"],  # Primary keys for ContentPulse\n",
        "        create_database_objects_if_missing=True,  # Auto-create PG objects\n",
        "        scheduling_policy=SyncedTableSchedulingPolicy.CONTINUOUS,\n",
        "        new_pipeline_spec=pipeline_spec\n",
        "    )\n",
        "    \n",
        "    # Create the synced database table\n",
        "    synced_table = w.database.create_synced_database_table(\n",
        "        synced_table=SyncedDatabaseTable(\n",
        "            name=SYNCED_TABLE_NAME,  # UC catalog.schema.table name\n",
        "            database_instance_name=LAKEBASE_INSTANCE_NAME, \n",
        "            logical_database_name=LAKEBASE_CATALOG_NAME,\n",
        "            spec=synced_spec\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Synced Table created!\")\n",
        "    print(f\"   Table Name: {synced_table.name}\")\n",
        "    print(f\"   Source: {FULL_TABLE_NAME}\")\n",
        "    print(f\"   Target Instance: {LAKEBASE_INSTANCE_NAME}\")\n",
        "    print(f\"   Scheduling: CONTINUOUS\")\n",
        "    print(f\"   Primary Keys: event_id, timestamp\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Error: {e}\")\n",
        "    print(f\"   Make sure source table '{FULL_TABLE_NAME}' exists and has data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Generate Connection Details for Dashboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate credentials for the Lakebase instance\n",
        "instance = w.database.get_database_instance(name=LAKEBASE_INSTANCE_NAME)\n",
        "credential = w.database.generate_database_credential(\n",
        "    instance_names=[LAKEBASE_INSTANCE_NAME]\n",
        ")\n",
        "\n",
        "host = instance.read_write_dns\n",
        "port = 5432\n",
        "dbname = LAKEBASE_CATALOG_NAME\n",
        "user = DB_USER_EMAIL\n",
        "password = credential.token\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üìù CONNECTION DETAILS FOR CONTENTPULSE DASHBOARD\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Host: {host}\")\n",
        "print(f\"Port: {port}\")\n",
        "print(f\"Database: {dbname}\")\n",
        "print(f\"User: {user}\")\n",
        "print(f\"Instance Name: {LAKEBASE_INSTANCE_NAME}\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ ContentPulse Lakebase Setup Complete!\n",
        "\n",
        "Your ContentPulse data is now syncing from Delta Lake to PostgreSQL for real-time dashboard access.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
